1. 内容简介

   1. 简介：将无序数据产生价值的过程

   2. 应用：

      1. 分类问题：图像识别，垃圾邮件识别；给出的是类别
      2. 回归问题：估价预测，房价预测；给出的数字
      3. 排序问题：点击率预估，推荐
      4. 生成问题：图像生成，风格转换，文字描述生成

   3. 算法：卷积，生成里面多；循环，不定长用的多；深度学习+强化学习

   4. 神经网络

      1. 神经元：多个输入产生一个输出；不同的特征值加权，补上常数项，再通过激活函数产生值

      2. 激活函数：产生非线性模型

         1. Sigmoid，值在0和1之间，对于单神经元能看成是二分概率事件的模型；对于多神经元，则是当前的值除以x加和，例子如下，即三个的概率

            ```javascript
            let Y = [y0, y1] = [2.8, 1.3]
            let eWx = [e28, e13]
            let sum = 2.8*e28 + 1.3*e13 + 1
            let Py0 = 2.8*e28 / sum
            let Py1 = 1.3*e13 / sum
            let Py2 = 1 / sum
            ```

      3. 目标函数，也是损失函数，衡量对数据的拟合程度

         1. y-modal(x)去看概率，具体的例子如下

            ```javascript
            [x, y] = [[1,2,3,4], 3]
            modal(x) = [0.1, 0.2, 0.3, 0.4, 0.5]
            // 如果y是二分就不用转换了
            // onehot下，根据y的label值，转换成矩阵
            y = [0, 0, 0, 1, 0]
            y - modal(x) = [0.1, 0.2, 0.3, 0.6, 0.5] = 1.7
            ```

         2. 目标函数分类

            1. 平方差损失函数
            2. 交叉熵，即yln( modal(x) )求和后平均

         3. 找最小值的过程采用梯度下降`k = k -αQ`Q是L对于k即所有参数集合的偏导，就是之前说的w和b，α是学习率

         4. 学习率

            1. 过大：先下降后上升，因为会越过低点
            2. 过小：太慢
            3. 大了一些：找不到最低点

      4. Tensorflow

         1. CIFAR-10进行图片分类训练：

            1. 图片展开方式，RR-GG-BB，对于32X32，就是1024+1024+1024

            2. 整理代码如下

               ```python
               image_arr = data['data'][100]
               image_arr = image_arr.reshape((3, 32, 32)) # 32 32 3
               image_arr = image_arr.transpose((1, 2, 0))
               matplot.imshow(image_arr) # 展示图片
               ```

            3. 图片的像素0-255要做预处理进行归一化，即x / 127.5 - 1就好

            4. 看测试集上面的准确性的时候是隔一定步数，比如5000次以后，拿出20个测试集进行平均准确度的计算

            5. 流程如下：

               1. 本身是声明式，先搭建计算图然后加数据
               2. [None, 3072]形式矩阵的x，[3072，1]形式的w，[None, 1]形式的b，y，构建loss和optimizer，初始化网络，设定步长和训练次数，搭建训练流程；这里的1对应的是一个类别，多类别就是多维度
               3. 单类别的激活函数是sigmoid；多类别的是softmax，且这时候要将y进行one_hot编码
               4. 读取图片，根据2提取像素矩阵，根据3归一化处理，得到图片的像素矩阵
               5. 进行1时候也拿到对应的label，得到x对应的y
               6. 4中的数据作为输入放到2搭建好的模型当中进行训练

         2. jupyter包进行程序

2. 卷积神经网络

   1. 多层网络
      1. 单层效果不行，使用更多层，就是一层一层加过去，上面说的偏导则采用链式法则可以计算出来，所以每次都计算所有层上面的偏导来减小loss
      2. 问题就是耗时且占内存；提出单样本，但是会过于收敛于这个单样本；提出随机的mini-batch作为样本
      3. Mini-batch产生的问题是梯度下降时候产生的震荡问题；局部极值点，因为有多个极值，在一个极值的周围会来回运动而跳不出去；saddle point，即某一点的偏导是0，这样点就停在那里
      4. 引出了动态梯度下降的方式，就是说将之前的梯度下降动量积累（类似动量求和后平均）和这一步的梯度下降动量相加；这样到达极值点的时候，因为有之前的动量积累就会跳出去；而局部震荡时候，两个震荡向量相加会使得点直接靠近内圈，加速了下降的过程
   2. 卷积网络
      1. 常规网络在识别图片时候的问题
         1. 图片的参数很多，导致生成的网络参数更多，带来的就是表达能力强，所以样本小的时候很容易过拟合
         2. 参数过多在梯度下降的时候容易产生问题，因为单个步骤很容易陷入到局部极值
      2. 解决方法，
         1. 利用就是图片局部有相关性的特地，将一片区域，比如10X10放到一起对一个神经元，而不是全连接，这样就减少了参数
         2. 参数共享，特定区域只是内部有关系而与位置无关，强制所有的10X10参数相同，这样就相当于是使用一个map不断扫过图片区域，和图片矩阵进行点积，得到一个小的图片矩阵作为这个图片的特征
         3. 2中的map就是卷积核，输入图像矩阵里面的值是位置，扫过的时候还有步长，即每次跳几个格子
         4. 一个问题是最后的矩阵会变小，可能缺失信息；padding就是说周围包裹若干层0，这样扫过得到的结果依旧还是原来图片矩阵大小的情况；
         5. 卷积核的意义是提取不同位置的特征
      3. 多通道：即有多通道卷积核，不同层的参数不共享，最后是每个通道上的结果和
      4. 结果多通道，即使用复数的多通道卷积核，产生的结果就是多通道的结果；也就是说多通道结果是不同提取特征手段产生的结果
      5. 激活函数，上面产生的结果经过激活函数，得到最后的值
         1. 很多种，sigmoid, tanh, ReLU, Leaky ReLU, Maxout, ELU
         2. 一般使用ReLU，即小于0是0，大于0就是x，因为快
         3. 单调和非线性：线性的话，多层网络可以合并，这样变深没有意义
      6. 池化，即用定长的map去扫，根据不同方式提取map中的特征值
         1. 一般按照平均值或者最大值
         2. 扫的时候不重叠且没有padding的过程
         3. 减少计算量，本身参数按照卷积核和步长来，不同也行
         4. 减少了平移问题，即移动后特征值一样的结果
         5. 损失了精度，即空间信息
      7. 全连接层，即将卷积层先展开成1维向量，然后和神经元11联通；注意后面不能再连卷积或者进行pooling，因为没有二维信息，本身参数很多
      8. 最后不做全连接层，进行反卷积的话生成和目标相同大的图片，用来进行img2img

3. CNN进阶

   1. 不同的模型使用场景不同，且各有优点和缺点，要相互借鉴
   2. 进化流程
      1. 变深变宽 - AlexNet到VGGNet
      2. 不同的模型结构 - VGG到EesNet
      3. 组合模型 Inception + ResNet
      4. 自学习 NASNet
      5. 手机端特化，MoblieNet
   3. AlexNet
      1. 开始的时候进行分层使用复数的GPU进行计算，经过一个卷积层后将结果合并在分别计算，最后进全连接
      2. 首次使用ReLU；2-GPU并行结构；1，2，5卷积层后跟随max-pooling层；两个全连层使用了dropout
      3. Dropout，即每次训练的时候随机mark一些本次不参与计算的神经元；即加速又避免过拟合
         1. 组合解释：每次相当于是使用了子网络，而最后训练的结果就是子网络的组合结果，组合的效果比较好
         2. 数据解释：因为减少了神经元也能拟合，相当于是一个图片进行了变化后去训练网络，所以数据增强了
         3. 动机：消除了网络中神经元的依赖关系，增强了网络本身的泛化效果
      4. 过拟合：对于样本的你和效果好但是对于新来的样本你和效果不好
      5. 参数相关：
         1. 数据增强，对于一张图片，[255, 255]随机得到大量的[224, 224]的结果
         2. Dropout = 0.5
         3. SGD里面动量积累的系数是0.9
         4. 学习率开始0.01，设定一定步长后变为之前的十分之一
         5. Batch-size是128
         6. 一共7个CN，即组合模型
   4. VGGNet
      1. 优点
         1. 更深：使用大量的3X3
         2. 提出视野域的概念：即两个3X3是5X5，两个5X5是两个7X7，要多用3X3，因为视野一样且多一次利用激活函数做的非线性变换，降低了参数
         3. 1X1可以看成是非线性变化：相当于是降低通道数目且提取特征，用1X1去做是将多通道上的单个位置进行激活函数处理，然后降低通道数
         4. 没经过一个pooling层应该将通道数目翻倍
      2. 数据增强方面：先扩大后再随机选[224, 224]
      3. 训练方面，因为是多层次的，所以可以先训练浅的，然后初始化后再训练深的
   5. ResNet
      1. VGGNet的问题：实验发现加深网络后错误率反而上升了
      2. 提出的想法就是，并不是深层学不到东西而是优化没有做好，所以对于深层，采用F(x) + x，然后再进激活函数的方式，这样深层网络至少能学到之前的东西
      3. 流程如下：普通卷积层，pooling，残差结构，跳过全连接直接输出
      4. 好处：
         1. 减少每层学习内容，之前是下一层要记住上一层的位置信息，所以是map-pooling-map-pooling，现在因为有残差，所以可以直接拿到上一层的信息
         2. 不同层的结构相近，有助于学习；因为跨层进行非线性变化的时候可能产生数值结构不同的问题，如[0, 512]到[512, 1024]这种，但因为有了x，所以F(x)小的时候，两层结构相近，这样不用同时兼顾两层，学习速度加快
      5. 多层时候数据经过两个网络后会降低维度，所以原来的x也要降维，使用pooling，之后因为维度降低但是通道数翻倍了，所以要padding增加上等大小的padding
      6. Global-pool，大小等于图的大小，即经过这个过程后图就是原来所有值的均值了
   6. InceptionNet
      1. 解决的是层次加深过拟合和错误率上升的问题；
      2. 稀疏矩阵类似dropout，减少了参数但是没有减少计算量，因为稀疏矩阵采用密集计算效率更高，所以还是有问题
      3. 提出了分组卷积，即采用不同的卷积核依次进行计算，之后把结果合并；例如本来是一个3X3然后产生400通道，现在就是1X1, 3X3, 5X5, 3X3 pooling四种方式各100个通道；这样减少了参数也减少了计算量
      4. 实际中注意pooling后记得padding
      5. 优化方案：比如5X5可以变成3X3；100通道可以通过多加一个1X1来减小通道；3X3也可以优化成1X3和3X1的矩阵；再加上残差
   7. MoblieNet
      1. 分组卷积的时候，每个神经元只做部分的通道而不是全部的通道，得到结构后再合并在一起
      2. 精度下降了但是速度变快参数减少

4. CNN参数问题

   1. 优化算法
      1. 梯度下降的问题：受限于初始学习率，且全局学习率一样的问题；
      2. AdaGrad算法：学习率除上以前所有梯度和的开方；这样开始很快后面比较慢，不同参数的学习率也不同；问题就是初始学习率有影响，因为会跳的过大，且后期会提早结束学习，因为梯度下降值大
      3. RMSProp，采用的是均值梯度
      4. Adam，将上面两个合在一起
      5. 自适应，即自己设置学习率的改变方式
      6. 对于稀疏数据，自适应的比较好
   2. 激活函数
      1. sigmoid问题：均值不是0；左右两侧快速收敛；计算复杂；反向传播的时候，因为本身导数是小数相乘，所以链式求导下会导致梯度消失
      2. Tanh：没有梯度，计算复杂，但是均值是0
      3. ReLu：计算简单，均值不是0，梯度为1不会饱和，收敛速度快，问题是小于0的部分会无法激活一直是0
      4. Leaky-ReLU：解决了小于0无法激活的问题
      5. ELU：类似上面，不过均值更接近0，但是计算量大
   3. 网络初始化
      1. 好的初始化方法是，经过多层NN，每次上面的分布都大概是正太分布到-1和1的区间内
      2. 不同的初始化方法对于不同的激活函数的效果不同
   4. BN，批归一化：即对于每一个batch里面的数据激活后再次进行归一化处理，即得到当前batch的x均值，然后将所有的x都减去均值，完成了批归一化；问题就是因为一个batch不能反映样本的情况，这样已经算好的网络就失效了，所以提出了逆归一化的思想，即将两个参数，对于上述产生的x并不是直接返回，而是引入两个参数，两个参数通过深度学习获得
   5. 数据增强
      1. 归一化的方式
      2. 图像变化：翻转，拉伸，裁剪，变形
      3. 色彩变化：对比度和亮度
      4. 多尺度裁剪，即上面的255变成224；流程就是随便选择数字，将图片变大然后去裁剪，获得最后的224
   6. 尝试正则化W，比如平方或者绝对值
   7. tensorBoard进行中间状态的输出
   8. Fine-tune，即利用已经训练好的模型作为初始化内容；每一步存储models，开始训练的时候重新装载，保持一些层级不变只训练一部分层级

