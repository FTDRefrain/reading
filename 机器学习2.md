1. 对抗神经网络

   1. DCGAN

      1. fractional-strided，反卷积：可以理解成先padding，然后使用卷积核扫过；也可以把卷积核看成一维向量，利用矩阵的原理可以知道，反卷积的反向传播梯度下降函数和卷积操作的正向传播梯度下降的过程一样
      2. 反卷积的方式：直接在周围加上padding。另一个是在每一个周围九宫格加上padding，即两个间有间隔。
      3. 将所有的pooling使用卷积替代。D是strided，G是反卷积，因为是向量生成图片，所以是反卷积
      4. 模型结构：
         1. G和D都是用了batch normalization，解决的是初始值不好，梯度下降的问题。经验上讲，不应该作用于输入层和输出层
         2. G上输出层使用的是tanh，其余层使用的是relu
         3. D上使用的是LeakReLu
      5. 应用上，因为是向量，所以存在加减的应用。比如复数有眼镜照片的向量均值减去一个人加上一个人，最后一个人就会戴上眼镜

   2. 图像翻译，Pix2Pix

      1. 即对于同一张图有不同的表达方式，比如背景色改变，实物图变成素描图

      2. G上面变成图像到图像；D上变成两个判断，是否是真实图像，是否是一对图像。即输入的时候是真实的图像对和G生成图像和目标图像对

      3. G结构：U-Net，大概的结构如下，依旧是先编码后解码，两部分对应层上的数据做了一个残差链接，ED是flatten的结果了，即256X256X3到ED的时候就是1X1X512

         ````javascript
         E1 ----------> D1
         	E2 -------> D2
         		E3 ---> D3
         			  ED
         ````

   3. 非配对图像翻译，cycleGAN

      1. 源于语言翻译，即好的翻译就是能翻译过去再翻译回来的。提出两套GAN
      2. 一套用于生成和判断，另一套用于转换回来内容的翻译和判断。
      3. 有效原因：因为转换过去再转换回来相当于加上了一致性约束，减少了搜索空间。
      4. 损失函数，两边GAN的loss加上λ乘上一致性损失函数(和G，F及x, y有关)
      5. 网络细节
         1. D的输入变为70*70来加快速度
         2. GAN的loss里面将里面的参数设置成平方，经验
         3. λ为10
         4. adam优化
         5. α前100次是0.0002，之后线性下降

   4. 多领域图像翻译

      1. 对于多要求的图像翻译，原来的网络仅支持1种到1种
      2. 提出starGAN，即提出一个中心，若干种的变化都可以通过这个中心转化后得到目标
      3. 大部分和之前的pix2pix一样，中间多了一个部分：将input和target domain作为输入放进去得到了fake，将这个fake和input的风格合并通过G得到第二个fake，第二个fake和input要进行一致性损失函数。而第一个fake则进入D去判断真假以及是否属于目标domain
      4. 上面的input和target domain合并的时候需要将domain embedding，考虑本身domain小而图像大，可以考虑加在中间，放头部也没有问题；
      5. 一个区别就是G和D的训练目标函数不同，不再是同一个函数最小化G最大化D了。

   5. 文本生成图像

      1. G的输入是文本+随机向量，因为输入不同可能对的是同一张图片；D的输入是fake加上文本向量，这里注意文本向量要在图像卷积展开中间拼接上去
      2. 训练集构建时候，可以先训练能否判断fake再训练是否匹配描述。另外训练集里面应该有，<真图，描述>，<假图，描述>，<真图，错误描述>

   6. DCGAN实战

      1. 模块构建
         1. Data provider: Image data and random vector
         2. compute graph: generator, discriminator, DCGAN
         3. training process
      2. 具体代码没有看

2. 自动机器学习网络

   1. 自动搜索网络结构；指定任务上通过fine-tune或者迁移学习拿到更好的结果